


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-90545585-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchvision.datasets &mdash; Torchvision master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torchvision.io" href="io.html" />
    <link rel="prev" title="torchvision" href="index.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/vision/versions.html'>master (0.9.0 ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">torchvision.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">torchvision.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">torchvision.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="ops.html">torchvision.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="transforms.html">torchvision.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torchvision.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torchvision.datasets</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/datasets.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="torchvision-datasets">
<h1>torchvision.datasets<a class="headerlink" href="#torchvision-datasets" title="Permalink to this headline">¶</a></h1>
<p>All datasets are subclasses of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code>
i.e, they have <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> and <code class="docutils literal notranslate"><span class="pre">__len__</span></code> methods implemented.
Hence, they can all be passed to a <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code>
which can load multiple samples in parallel using <code class="docutils literal notranslate"><span class="pre">torch.multiprocessing</span></code> workers.
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">imagenet_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageNet</span><span class="p">(</span><span class="s1">&#39;path/to/imagenet_root/&#39;</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">imagenet_data</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">nThreads</span><span class="p">)</span>
</pre></div>
</div>
<p>The following datasets are available:</p>
<div class="contents local topic" id="datasets">
<p class="topic-title">Datasets</p>
<ul class="simple">
<li><a class="reference internal" href="#celeba" id="id18">CelebA</a></li>
<li><a class="reference internal" href="#cifar" id="id19">CIFAR</a></li>
<li><a class="reference internal" href="#cityscapes" id="id20">Cityscapes</a></li>
<li><a class="reference internal" href="#coco" id="id21">COCO</a><ul>
<li><a class="reference internal" href="#captions" id="id22">Captions</a></li>
<li><a class="reference internal" href="#detection" id="id23">Detection</a></li>
</ul>
</li>
<li><a class="reference internal" href="#datasetfolder" id="id24">DatasetFolder</a></li>
<li><a class="reference internal" href="#emnist" id="id25">EMNIST</a></li>
<li><a class="reference internal" href="#fakedata" id="id26">FakeData</a></li>
<li><a class="reference internal" href="#fashion-mnist" id="id27">Fashion-MNIST</a></li>
<li><a class="reference internal" href="#flickr" id="id28">Flickr</a></li>
<li><a class="reference internal" href="#hmdb51" id="id29">HMDB51</a></li>
<li><a class="reference internal" href="#imagefolder" id="id30">ImageFolder</a></li>
<li><a class="reference internal" href="#imagenet" id="id31">ImageNet</a></li>
<li><a class="reference internal" href="#kinetics-400" id="id32">Kinetics-400</a></li>
<li><a class="reference internal" href="#kmnist" id="id33">KMNIST</a></li>
<li><a class="reference internal" href="#lsun" id="id34">LSUN</a></li>
<li><a class="reference internal" href="#mnist" id="id35">MNIST</a></li>
<li><a class="reference internal" href="#omniglot" id="id36">Omniglot</a></li>
<li><a class="reference internal" href="#phototour" id="id37">PhotoTour</a></li>
<li><a class="reference internal" href="#places365" id="id38">Places365</a></li>
<li><a class="reference internal" href="#qmnist" id="id39">QMNIST</a></li>
<li><a class="reference internal" href="#sbd" id="id40">SBD</a></li>
<li><a class="reference internal" href="#sbu" id="id41">SBU</a></li>
<li><a class="reference internal" href="#stl10" id="id42">STL10</a></li>
<li><a class="reference internal" href="#svhn" id="id43">SVHN</a></li>
<li><a class="reference internal" href="#ucf101" id="id44">UCF101</a></li>
<li><a class="reference internal" href="#usps" id="id45">USPS</a></li>
<li><a class="reference internal" href="#voc" id="id46">VOC</a></li>
</ul>
</div>
<p>All the datasets have almost similar API. They all have two common arguments:
<code class="docutils literal notranslate"><span class="pre">transform</span></code> and  <code class="docutils literal notranslate"><span class="pre">target_transform</span></code> to transform the input and target respectively.</p>
<div class="section" id="celeba">
<h2><a class="toc-backref" href="#id18">CelebA</a><a class="headerlink" href="#celeba" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.CelebA">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">CelebA</code><span class="sig-paren">(</span><em>root: str, split: str = 'train', target_type: Union[List[str], str] = 'attr', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/celeba.html#CelebA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CelebA" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Large-scale CelebFaces Attributes (CelebA) Dataset</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</li>
<li><strong>split</strong> (<em>string</em>) – One of {‘train’, ‘valid’, ‘test’, ‘all’}.
Accordingly dataset is selected.</li>
<li><strong>target_type</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em>, </em><em>optional</em>) – <p>Type of target to use, <code class="docutils literal notranslate"><span class="pre">attr</span></code>, <code class="docutils literal notranslate"><span class="pre">identity</span></code>, <code class="docutils literal notranslate"><span class="pre">bbox</span></code>,
or <code class="docutils literal notranslate"><span class="pre">landmarks</span></code>. Can also be a list to output a tuple with all specified target types.
The targets represent:</p>
<blockquote>
<div><ul>
<li><code class="docutils literal notranslate"><span class="pre">attr</span></code> (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes</li>
<li><code class="docutils literal notranslate"><span class="pre">identity</span></code> (int): label for each person (data points with the same identity are the same person)</li>
<li><code class="docutils literal notranslate"><span class="pre">bbox</span></code> (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)</li>
<li><code class="docutils literal notranslate"><span class="pre">landmarks</span></code> (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,
righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)</li>
</ul>
</div></blockquote>
<p>Defaults to <code class="docutils literal notranslate"><span class="pre">attr</span></code>. If empty, <code class="docutils literal notranslate"><span class="pre">None</span></code> will be returned as target.</p>
</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cifar">
<h2><a class="toc-backref" href="#id19">CIFAR</a><a class="headerlink" href="#cifar" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.CIFAR10">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">CIFAR10</code><span class="sig-paren">(</span><em>root: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/cifar.html#CIFAR10"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CIFAR10" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">cifar-10-batches-py</span></code> exists or will be saved to if download is set to True.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from training set, otherwise
creates from test set.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.CIFAR10.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/cifar.html#CIFAR10.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CIFAR10.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is index of the target class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.CIFAR100">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">CIFAR100</code><span class="sig-paren">(</span><em>root: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/cifar.html#CIFAR100"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CIFAR100" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR100</a> Dataset.</p>
<p>This is a subclass of the <cite>CIFAR10</cite> Dataset.</p>
</dd></dl>

</div>
<div class="section" id="cityscapes">
<h2><a class="toc-backref" href="#id20">Cityscapes</a><a class="headerlink" href="#cityscapes" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Requires Cityscape to be downloaded.</p>
</div>
<dl class="class">
<dt id="torchvision.datasets.Cityscapes">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">Cityscapes</code><span class="sig-paren">(</span><em>root: str, split: str = 'train', mode: str = 'fine', target_type: Union[List[str], str] = 'instance', transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, transforms: Union[Callable, NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/cityscapes.html#Cityscapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Cityscapes" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.cityscapes-dataset.com/">Cityscapes</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory <code class="docutils literal notranslate"><span class="pre">leftImg8bit</span></code>
and <code class="docutils literal notranslate"><span class="pre">gtFine</span></code> or <code class="docutils literal notranslate"><span class="pre">gtCoarse</span></code> are located.</li>
<li><strong>split</strong> (<em>string</em><em>, </em><em>optional</em>) – The image split to use, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">test</span></code> or <code class="docutils literal notranslate"><span class="pre">val</span></code> if mode=”fine”
otherwise <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">train_extra</span></code> or <code class="docutils literal notranslate"><span class="pre">val</span></code></li>
<li><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – The quality mode to use, <code class="docutils literal notranslate"><span class="pre">fine</span></code> or <code class="docutils literal notranslate"><span class="pre">coarse</span></code></li>
<li><strong>target_type</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em>, </em><em>optional</em>) – Type of target to use, <code class="docutils literal notranslate"><span class="pre">instance</span></code>, <code class="docutils literal notranslate"><span class="pre">semantic</span></code>, <code class="docutils literal notranslate"><span class="pre">polygon</span></code>
or <code class="docutils literal notranslate"><span class="pre">color</span></code>. Can also be a list to output a tuple with all specified target types.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Get semantic segmentation target</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Cityscapes</span><span class="p">(</span><span class="s1">&#39;./data/cityscapes&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fine&#39;</span><span class="p">,</span>
                     <span class="n">target_type</span><span class="o">=</span><span class="s1">&#39;semantic&#39;</span><span class="p">)</span>

<span class="n">img</span><span class="p">,</span> <span class="n">smnt</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Get multiple targets</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Cityscapes</span><span class="p">(</span><span class="s1">&#39;./data/cityscapes&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fine&#39;</span><span class="p">,</span>
                     <span class="n">target_type</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;instance&#39;</span><span class="p">,</span> <span class="s1">&#39;color&#39;</span><span class="p">,</span> <span class="s1">&#39;polygon&#39;</span><span class="p">])</span>

<span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">inst</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">poly</span><span class="p">)</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Validate on the “coarse” set</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Cityscapes</span><span class="p">(</span><span class="s1">&#39;./data/cityscapes&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;coarse&#39;</span><span class="p">,</span>
                     <span class="n">target_type</span><span class="o">=</span><span class="s1">&#39;semantic&#39;</span><span class="p">)</span>

<span class="n">img</span><span class="p">,</span> <span class="n">smnt</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<dl class="method">
<dt id="torchvision.datasets.Cityscapes.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/cityscapes.html#Cityscapes.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Cityscapes.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is a tuple of all target types if target_type is a list with more
than one item. Otherwise target is a json object if target_type=”polygon”, else the image segmentation.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="coco">
<h2><a class="toc-backref" href="#id21">COCO</a><a class="headerlink" href="#coco" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">These require the <a class="reference external" href="https://github.com/pdollar/coco/tree/master/PythonAPI">COCO API to be installed</a></p>
</div>
<div class="section" id="captions">
<h3><a class="toc-backref" href="#id22">Captions</a><a class="headerlink" href="#captions" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchvision.datasets.CocoCaptions">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">CocoCaptions</code><span class="sig-paren">(</span><em>root: str</em>, <em>annFile: str</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>transforms: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/coco.html#CocoCaptions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CocoCaptions" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://cocodataset.org/#captions-2015">MS Coco Captions</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</li>
<li><strong>annFile</strong> (<em>string</em>) – Path to json annotation file.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dset</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">CocoCaptions</span><span class="p">(</span><span class="n">root</span> <span class="o">=</span> <span class="s1">&#39;dir where images are&#39;</span><span class="p">,</span>
                        <span class="n">annFile</span> <span class="o">=</span> <span class="s1">&#39;json annotation file&#39;</span><span class="p">,</span>
                        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of samples: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cap</span><span class="p">))</span>
<span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">cap</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="c1"># load 4th sample</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image Size: &quot;</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">samples</span><span class="p">:</span> <span class="mi">82783</span>
<span class="n">Image</span> <span class="n">Size</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="n">L</span><span class="p">,</span> <span class="mi">427</span><span class="n">L</span><span class="p">,</span> <span class="mi">640</span><span class="n">L</span><span class="p">)</span>
<span class="p">[</span><span class="sa">u</span><span class="s1">&#39;A plane emitting smoke stream flying over a mountain.&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A plane darts across a bright blue sky behind a mountain covered in snow&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A plane leaves a contrail above the snowy mountain top.&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A mountain that has a plane flying overheard in the distance.&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A mountain view with a plume of smoke in the background&#39;</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="detection">
<h3><a class="toc-backref" href="#id23">Detection</a><a class="headerlink" href="#detection" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchvision.datasets.CocoDetection">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">CocoDetection</code><span class="sig-paren">(</span><em>root: str</em>, <em>annFile: str</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>transforms: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/coco.html#CocoDetection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CocoDetection" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://cocodataset.org/#detection-2016">MS Coco Detection</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</li>
<li><strong>annFile</strong> (<em>string</em>) – Path to json annotation file.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>
<div class="section" id="datasetfolder">
<h2><a class="toc-backref" href="#id24">DatasetFolder</a><a class="headerlink" href="#datasetfolder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.DatasetFolder">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">DatasetFolder</code><span class="sig-paren">(</span><em>root: str, loader: Callable[[str], Any], extensions: Union[Tuple[str, ...], NoneType] = None, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, is_valid_file: Union[Callable[[str], bool], NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/folder.html#DatasetFolder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.DatasetFolder" title="Permalink to this definition">¶</a></dt>
<dd><p>A generic data loader where the samples are arranged in this way:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">/</span><span class="n">class_x</span><span class="o">/</span><span class="n">xxx</span><span class="o">.</span><span class="n">ext</span>
<span class="n">root</span><span class="o">/</span><span class="n">class_x</span><span class="o">/</span><span class="n">xxy</span><span class="o">.</span><span class="n">ext</span>
<span class="n">root</span><span class="o">/</span><span class="n">class_x</span><span class="o">/</span><span class="p">[</span><span class="o">...</span><span class="p">]</span><span class="o">/</span><span class="n">xxz</span><span class="o">.</span><span class="n">ext</span>

<span class="n">root</span><span class="o">/</span><span class="n">class_y</span><span class="o">/</span><span class="mf">123.</span><span class="n">ext</span>
<span class="n">root</span><span class="o">/</span><span class="n">class_y</span><span class="o">/</span><span class="n">nsdf3</span><span class="o">.</span><span class="n">ext</span>
<span class="n">root</span><span class="o">/</span><span class="n">class_y</span><span class="o">/</span><span class="p">[</span><span class="o">...</span><span class="p">]</span><span class="o">/</span><span class="n">asd932_</span><span class="o">.</span><span class="n">ext</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory path.</li>
<li><strong>loader</strong> (<em>callable</em>) – A function to load a sample given its path.</li>
<li><strong>extensions</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>[</em><em>string</em><em>]</em>) – A list of allowed extensions.
both extensions and is_valid_file should not be passed.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in
a sample and returns a transformed version.
E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code> for images.</li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes
in the target and transforms it.</li>
<li><strong>is_valid_file</strong> – A function that takes path of a file
and check if the file is a valid file (used to check of corrupt files)
both extensions and is_valid_file should not be passed.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.DatasetFolder.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/folder.html#DatasetFolder.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.DatasetFolder.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(sample, target) where target is class_index of the target class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="emnist">
<h2><a class="toc-backref" href="#id25">EMNIST</a><a class="headerlink" href="#emnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.EMNIST">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">EMNIST</code><span class="sig-paren">(</span><em>root: str</em>, <em>split: str</em>, <em>**kwargs</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/mnist.html#EMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.EMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.westernsydney.edu.au/bens/home/reproducible_research/emnist">EMNIST</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">EMNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">EMNIST/processed/test.pt</span></code> exist.</li>
<li><strong>split</strong> (<em>string</em>) – The dataset has 6 different splits: <code class="docutils literal notranslate"><span class="pre">byclass</span></code>, <code class="docutils literal notranslate"><span class="pre">bymerge</span></code>,
<code class="docutils literal notranslate"><span class="pre">balanced</span></code>, <code class="docutils literal notranslate"><span class="pre">letters</span></code>, <code class="docutils literal notranslate"><span class="pre">digits</span></code> and <code class="docutils literal notranslate"><span class="pre">mnist</span></code>. This argument specifies
which one to use.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="fakedata">
<h2><a class="toc-backref" href="#id26">FakeData</a><a class="headerlink" href="#fakedata" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.FakeData">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">FakeData</code><span class="sig-paren">(</span><em>size: int = 1000</em>, <em>image_size: Tuple[int</em>, <em>int</em>, <em>int] = (3</em>, <em>224</em>, <em>224)</em>, <em>num_classes: int = 10</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>random_offset: int = 0</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/fakedata.html#FakeData"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.FakeData" title="Permalink to this definition">¶</a></dt>
<dd><p>A fake dataset that returns randomly generated images and returns them as PIL images</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Size of the dataset. Default: 1000 images</li>
<li><strong>image_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size if the returned images. Default: (3, 224, 224)</li>
<li><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Number of classes in the datset. Default: 10</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>random_offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Offsets the index-based random seed used to
generate each image. Default: 0</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="fashion-mnist">
<h2><a class="toc-backref" href="#id27">Fashion-MNIST</a><a class="headerlink" href="#fashion-mnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.FashionMNIST">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">FashionMNIST</code><span class="sig-paren">(</span><em>root: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/mnist.html#FashionMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.FashionMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">FashionMNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">FashionMNIST/processed/test.pt</span></code> exist.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="flickr">
<h2><a class="toc-backref" href="#id28">Flickr</a><a class="headerlink" href="#flickr" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Flickr8k">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">Flickr8k</code><span class="sig-paren">(</span><em>root: str</em>, <em>ann_file: str</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr8k"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr8k" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://hockenmaier.cs.illinois.edu/8k-pictures.html">Flickr8k Entities</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</li>
<li><strong>ann_file</strong> (<em>string</em>) – Path to annotation file.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.Flickr8k.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr8k.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr8k.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Tuple (image, target). target is a list of captions for the image.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.Flickr30k">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">Flickr30k</code><span class="sig-paren">(</span><em>root: str</em>, <em>ann_file: str</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr30k"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr30k" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/">Flickr30k Entities</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</li>
<li><strong>ann_file</strong> (<em>string</em>) – Path to annotation file.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.Flickr30k.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr30k.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr30k.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Tuple (image, target). target is a list of captions for the image.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="hmdb51">
<h2><a class="toc-backref" href="#id29">HMDB51</a><a class="headerlink" href="#hmdb51" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.HMDB51">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">HMDB51</code><span class="sig-paren">(</span><em>root</em>, <em>annotation_path</em>, <em>frames_per_clip</em>, <em>step_between_clips=1</em>, <em>frame_rate=None</em>, <em>fold=1</em>, <em>train=True</em>, <em>transform=None</em>, <em>_precomputed_metadata=None</em>, <em>num_workers=1</em>, <em>_video_width=0</em>, <em>_video_height=0</em>, <em>_video_min_dimension=0</em>, <em>_audio_samples=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/hmdb51.html#HMDB51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.HMDB51" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/">HMDB51</a>
dataset.</p>
<p>HMDB51 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip is given by
<code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively, if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code>
and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all
frames in a video might be present.</p>
<p>Internally, it uses a VideoClips object to handle clip creation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the HMDB51 Dataset.</li>
<li><strong>annotation_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Path to the folder containing the split files.</li>
<li><strong>frames_per_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of frames in a clip.</li>
<li><strong>step_between_clips</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of frames between each clip.</li>
<li><strong>fold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Which fold to use. Should be between 1 and 3.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, creates a dataset from the train split,
otherwise from the <code class="docutils literal notranslate"><span class="pre">test</span></code> split.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a TxHxWxC video
and returns a transformed version.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>A 3-tuple with the following entries:</p>
<blockquote>
<div><ul class="simple">
<li>video (Tensor[T, H, W, C]): The <cite>T</cite> video frames</li>
<li>audio(Tensor[K, L]): the audio frames, where <cite>K</cite> is the number of channels
and <cite>L</cite> is the number of points</li>
<li>label (int): class of the video clip</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="imagefolder">
<h2><a class="toc-backref" href="#id30">ImageFolder</a><a class="headerlink" href="#imagefolder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.ImageFolder">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">ImageFolder</code><span class="sig-paren">(</span><em>root: str, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, loader: Callable[[str], Any] = &lt;function default_loader&gt;, is_valid_file: Union[Callable[[str], bool], NoneType] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/folder.html#ImageFolder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.ImageFolder" title="Permalink to this definition">¶</a></dt>
<dd><p>A generic data loader where the images are arranged in this way:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">/</span><span class="n">dog</span><span class="o">/</span><span class="n">xxx</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">dog</span><span class="o">/</span><span class="n">xxy</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">dog</span><span class="o">/</span><span class="p">[</span><span class="o">...</span><span class="p">]</span><span class="o">/</span><span class="n">xxz</span><span class="o">.</span><span class="n">png</span>

<span class="n">root</span><span class="o">/</span><span class="n">cat</span><span class="o">/</span><span class="mf">123.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">cat</span><span class="o">/</span><span class="n">nsdf3</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">cat</span><span class="o">/</span><span class="p">[</span><span class="o">...</span><span class="p">]</span><span class="o">/</span><span class="n">asd932_</span><span class="o">.</span><span class="n">png</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory path.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>loader</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function to load an image given its path.</li>
<li><strong>is_valid_file</strong> – A function that takes path of an Image file
and check if the file is a valid file (used to check of corrupt files)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.ImageFolder.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="headerlink" href="#torchvision.datasets.ImageFolder.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(sample, target) where target is class_index of the target class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="imagenet">
<h2><a class="toc-backref" href="#id31">ImageNet</a><a class="headerlink" href="#imagenet" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.ImageNet">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">ImageNet</code><span class="sig-paren">(</span><em>root: str</em>, <em>split: str = 'train'</em>, <em>download: Union[str</em>, <em>NoneType] = None</em>, <em>**kwargs</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/imagenet.html#ImageNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.ImageNet" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://image-net.org/">ImageNet</a> 2012 Classification Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the ImageNet Dataset.</li>
<li><strong>split</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset split, supports <code class="docutils literal notranslate"><span class="pre">train</span></code>, or <code class="docutils literal notranslate"><span class="pre">val</span></code>.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>loader</strong> – A function to load an image given its path.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This requires <cite>scipy</cite> to be installed</p>
</div>
</div>
<div class="section" id="kinetics-400">
<h2><a class="toc-backref" href="#id32">Kinetics-400</a><a class="headerlink" href="#kinetics-400" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Kinetics400">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">Kinetics400</code><span class="sig-paren">(</span><em>root</em>, <em>frames_per_clip</em>, <em>step_between_clips=1</em>, <em>frame_rate=None</em>, <em>extensions=('avi'</em>, <em>)</em>, <em>transform=None</em>, <em>_precomputed_metadata=None</em>, <em>num_workers=1</em>, <em>_video_width=0</em>, <em>_video_height=0</em>, <em>_video_min_dimension=0</em>, <em>_audio_samples=0</em>, <em>_audio_channels=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/kinetics.html#Kinetics400"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Kinetics400" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">Kinetics-400</a>
dataset.</p>
<p>Kinetics-400 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip is given by
<code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively, if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code>
and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all
frames in a video might be present.</p>
<p>Internally, it uses a VideoClips object to handle clip creation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the Kinetics-400 Dataset.</li>
<li><strong>frames_per_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of frames in a clip</li>
<li><strong>step_between_clips</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of frames between each clip</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in a TxHxWxC video
and returns a transformed version.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>A 3-tuple with the following entries:</p>
<blockquote>
<div><ul class="simple">
<li>video (Tensor[T, H, W, C]): the <cite>T</cite> video frames</li>
<li>audio(Tensor[K, L]): the audio frames, where <cite>K</cite> is the number of channels
and <cite>L</cite> is the number of points</li>
<li>label (int): class of the video clip</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="kmnist">
<h2><a class="toc-backref" href="#id33">KMNIST</a><a class="headerlink" href="#kmnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.KMNIST">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">KMNIST</code><span class="sig-paren">(</span><em>root: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/mnist.html#KMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.KMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/rois-codh/kmnist">Kuzushiji-MNIST</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">KMNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">KMNIST/processed/test.pt</span></code> exist.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="lsun">
<h2><a class="toc-backref" href="#id34">LSUN</a><a class="headerlink" href="#lsun" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.LSUN">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">LSUN</code><span class="sig-paren">(</span><em>root: str</em>, <em>classes: Union[str</em>, <em>List[str]] = 'train'</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/lsun.html#LSUN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.LSUN" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.yf.io/p/lsun">LSUN</a> dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory for the database files.</li>
<li><strong>classes</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – One of {‘train’, ‘val’, ‘test’} or a list of
categories to load. e,g. [‘bedroom_train’, ‘church_outdoor_train’].</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.LSUN.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/lsun.html#LSUN.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.LSUN.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Tuple (image, target) where target is the index of the target category.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="mnist">
<h2><a class="toc-backref" href="#id35">MNIST</a><a class="headerlink" href="#mnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.MNIST">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">MNIST</code><span class="sig-paren">(</span><em>root: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/mnist.html#MNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.MNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">MNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">MNIST/processed/test.pt</span></code> exist.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="omniglot">
<h2><a class="toc-backref" href="#id36">Omniglot</a><a class="headerlink" href="#omniglot" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Omniglot">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">Omniglot</code><span class="sig-paren">(</span><em>root: str</em>, <em>background: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/omniglot.html#Omniglot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Omniglot" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/brendenlake/omniglot">Omniglot</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">omniglot-py</span></code> exists.</li>
<li><strong>background</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from the “background” set, otherwise
creates from the “evaluation” set. This terminology is defined by the authors.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset zip files from the internet and
puts it in root directory. If the zip files are already downloaded, they are not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="phototour">
<h2><a class="toc-backref" href="#id37">PhotoTour</a><a class="headerlink" href="#phototour" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.PhotoTour">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">PhotoTour</code><span class="sig-paren">(</span><em>root: str</em>, <em>name: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/phototour.html#PhotoTour"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.PhotoTour" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://phototour.cs.washington.edu/patches/default.htm">Learning Local Image Descriptors Data</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory where images are.</li>
<li><strong>name</strong> (<em>string</em>) – Name of the dataset to load.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.PhotoTour.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[Any, Any, torch.Tensor]]<a class="reference internal" href="_modules/torchvision/datasets/phototour.html#PhotoTour.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.PhotoTour.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(data1, data2, matches)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="places365">
<h2><a class="toc-backref" href="#id38">Places365</a><a class="headerlink" href="#places365" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Places365">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">Places365</code><span class="sig-paren">(</span><em>root: str, split: str = 'train-standard', small: bool = False, download: bool = False, transform: Union[Callable, NoneType] = None, target_transform: Union[Callable, NoneType] = None, loader: Callable[[str], Any] = &lt;function default_loader&gt;</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/places365.html#Places365"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Places365" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://places2.csail.mit.edu/index.html">Places365</a> classification dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the Places365 dataset.</li>
<li><strong>split</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset split. Can be one of <code class="docutils literal notranslate"><span class="pre">train-standard</span></code> (default), <code class="docutils literal notranslate"><span class="pre">train-challendge</span></code>,
<code class="docutils literal notranslate"><span class="pre">val</span></code>.</li>
<li><strong>small</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, uses the small images, i. e. resized to 256 x 256 pixels, instead of the
high resolution ones.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, downloads the dataset components and places them in <code class="docutils literal notranslate"><span class="pre">root</span></code>. Already
downloaded archives are not downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>loader</strong> – A function to load an image given its path.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><ul class="first last simple">
<li><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.9)"><code class="xref py py-exc docutils literal notranslate"><span class="pre">RuntimeError</span></code></a> – If <code class="docutils literal notranslate"><span class="pre">download</span> <span class="pre">is</span> <span class="pre">False</span></code> and the meta files, i. e. the devkit, are not present or corrupted.</li>
<li><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.9)"><code class="xref py py-exc docutils literal notranslate"><span class="pre">RuntimeError</span></code></a> – If <code class="docutils literal notranslate"><span class="pre">download</span> <span class="pre">is</span> <span class="pre">True</span></code> and the image archive is already extracted.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="qmnist">
<h2><a class="toc-backref" href="#id39">QMNIST</a><a class="headerlink" href="#qmnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.QMNIST">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">QMNIST</code><span class="sig-paren">(</span><em>root: str</em>, <em>what: Union[str</em>, <em>NoneType] = None</em>, <em>compat: bool = True</em>, <em>train: bool = True</em>, <em>**kwargs</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/mnist.html#QMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.QMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/facebookresearch/qmnist">QMNIST</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset whose <code class="docutils literal notranslate"><span class="pre">processed</span></code>
subdir contains torch binary files with the datasets.</li>
<li><strong>what</strong> (<em>string</em><em>,</em><em>optional</em>) – Can be ‘train’, ‘test’, ‘test10k’,
‘test50k’, or ‘nist’ for respectively the mnist compatible
training set, the 60k qmnist testing set, the 10k qmnist
examples that match the mnist testing set, the 50k
remaining qmnist testing examples, or all the nist
digits. The default is to select ‘train’ or ‘test’
according to the compatibility argument ‘train’.</li>
<li><strong>compat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>,</em><em>optional</em>) – A boolean that says whether the target
for each example is class number (for compatibility with
the MNIST dataloader) or a torch vector containing the
full qmnist information. Default=True.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from
the internet and puts it in root directory. If dataset is
already downloaded, it is not downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that
takes in an PIL image and returns a transformed
version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform
that takes in the target and transforms it.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>,</em><em>optional</em><em>,</em><em>compatibility</em>) – When argument ‘what’ is
not specified, this boolean decides whether to load the
training set ot the testing set.  Default: True.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="sbd">
<h2><a class="toc-backref" href="#id40">SBD</a><a class="headerlink" href="#sbd" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SBDataset">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">SBDataset</code><span class="sig-paren">(</span><em>root: str</em>, <em>image_set: str = 'train'</em>, <em>mode: str = 'boundaries'</em>, <em>download: bool = False</em>, <em>transforms: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/sbd.html#SBDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SBDataset" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://home.bharathh.info/pubs/codes/SBD/download.html">Semantic Boundaries Dataset</a></p>
<p>The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Please note that the train and val splits included with this dataset are different from
the splits in the PASCAL VOC dataset. In particular some “train” images might be part of
VOC2012 val.
If you are interested in testing on VOC 2012 val, then use <cite>image_set=’train_noval’</cite>,
which excludes all val images.</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This class needs <a class="reference external" href="https://docs.scipy.org/doc/">scipy</a> to load target files from <cite>.mat</cite> format.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the Semantic Boundaries Dataset</li>
<li><strong>image_set</strong> (<em>string</em><em>, </em><em>optional</em>) – Select the image_set to use, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">val</span></code> or <code class="docutils literal notranslate"><span class="pre">train_noval</span></code>.
Image set <code class="docutils literal notranslate"><span class="pre">train_noval</span></code> excludes VOC 2012 val images.</li>
<li><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – Select target type. Possible values ‘boundaries’ or ‘segmentation’.
In case of ‘boundaries’, the target is an array of shape <cite>[num_classes, H, W]</cite>,
where <cite>num_classes=20</cite>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
<li><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version. Input sample is PIL image and target is a numpy array
if <cite>mode=’boundaries’</cite> or PIL image if <cite>mode=’segmentation’</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="sbu">
<h2><a class="toc-backref" href="#id41">SBU</a><a class="headerlink" href="#sbu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SBU">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">SBU</code><span class="sig-paren">(</span><em>root: str</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = True</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/sbu.html#SBU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SBU" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.cs.virginia.edu/~vicente/sbucaptions/">SBU Captioned Photo</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where tarball
<code class="docutils literal notranslate"><span class="pre">SBUCaptionedPhotoDataset.tar.gz</span></code> exists.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.SBU.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/sbu.html#SBU.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SBU.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is a caption for the photo.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="stl10">
<h2><a class="toc-backref" href="#id42">STL10</a><a class="headerlink" href="#stl10" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.STL10">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">STL10</code><span class="sig-paren">(</span><em>root: str</em>, <em>split: str = 'train'</em>, <em>folds: Union[int</em>, <em>NoneType] = None</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/stl10.html#STL10"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.STL10" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://cs.stanford.edu/~acoates/stl10/">STL10</a> Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">stl10_binary</span></code> exists.</li>
<li><strong>split</strong> (<em>string</em>) – One of {‘train’, ‘test’, ‘unlabeled’, ‘train+unlabeled’}.
Accordingly dataset is selected.</li>
<li><strong>folds</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – One of {0-9} or None.
For training, loads one of the 10 pre-defined folds of 1k samples for the
standard evaluation procedure. If no value is passed, loads the 5k samples.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.STL10.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/stl10.html#STL10.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.STL10.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is index of the target class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="svhn">
<h2><a class="toc-backref" href="#id43">SVHN</a><a class="headerlink" href="#svhn" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SVHN">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">SVHN</code><span class="sig-paren">(</span><em>root: str</em>, <em>split: str = 'train'</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/svhn.html#SVHN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SVHN" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://ufldl.stanford.edu/housenumbers/">SVHN</a> Dataset.
Note: The SVHN dataset assigns the label <cite>10</cite> to the digit <cite>0</cite>. However, in this Dataset,
we assign the label <cite>0</cite> to the digit <cite>0</cite> to be compatible with PyTorch loss functions which
expect the class labels to be in the range <cite>[0, C-1]</cite></p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This class needs <a class="reference external" href="https://docs.scipy.org/doc/">scipy</a> to load data from <cite>.mat</cite> format.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">SVHN</span></code> exists.</li>
<li><strong>split</strong> (<em>string</em>) – One of {‘train’, ‘test’, ‘extra’}.
Accordingly dataset is selected. ‘extra’ is Extra training set.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.SVHN.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/svhn.html#SVHN.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SVHN.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is index of the target class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="ucf101">
<h2><a class="toc-backref" href="#id44">UCF101</a><a class="headerlink" href="#ucf101" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.UCF101">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">UCF101</code><span class="sig-paren">(</span><em>root</em>, <em>annotation_path</em>, <em>frames_per_clip</em>, <em>step_between_clips=1</em>, <em>frame_rate=None</em>, <em>fold=1</em>, <em>train=True</em>, <em>transform=None</em>, <em>_precomputed_metadata=None</em>, <em>num_workers=1</em>, <em>_video_width=0</em>, <em>_video_height=0</em>, <em>_video_min_dimension=0</em>, <em>_audio_samples=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/ucf101.html#UCF101"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.UCF101" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.crcv.ucf.edu/data/UCF101.php">UCF101</a> dataset.</p>
<p>UCF101 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip is given by
<code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively, if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code>
and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all
frames in a video might be present.</p>
<p>Internally, it uses a VideoClips object to handle clip creation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the UCF101 Dataset.</li>
<li><strong>annotation_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – path to the folder containing the split files</li>
<li><strong>frames_per_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of frames in a clip.</li>
<li><strong>step_between_clips</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – number of frames between each clip.</li>
<li><strong>fold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – which fold to use. Should be between 1 and 3.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, creates a dataset from the train split,
otherwise from the <code class="docutils literal notranslate"><span class="pre">test</span></code> split.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in a TxHxWxC video
and returns a transformed version.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>A 3-tuple with the following entries:</p>
<blockquote>
<div><ul class="simple">
<li>video (Tensor[T, H, W, C]): the <cite>T</cite> video frames</li>
<li>audio(Tensor[K, L]): the audio frames, where <cite>K</cite> is the number of channels
and <cite>L</cite> is the number of points</li>
<li>label (int): class of the video clip</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="usps">
<h2><a class="toc-backref" href="#id45">USPS</a><a class="headerlink" href="#usps" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.USPS">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">USPS</code><span class="sig-paren">(</span><em>root: str</em>, <em>train: bool = True</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>download: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/torchvision/datasets/usps.html#USPS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.USPS" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#usps">USPS</a> Dataset.
The data-format is : [label [index:value ]*256 n] * num_lines, where <code class="docutils literal notranslate"><span class="pre">label</span></code> lies in <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">10]</span></code>.
The value for each pixel lies in <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code>. Here we transform the <code class="docutils literal notranslate"><span class="pre">label</span></code> into <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">9]</span></code>
and make pixel values in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">255]</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of dataset to store``USPS`` data files.</li>
<li><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">usps.bz2</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">usps.t.bz2</span></code>.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.USPS.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/usps.html#USPS.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.USPS.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is index of the target class.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="voc">
<h2><a class="toc-backref" href="#id46">VOC</a><a class="headerlink" href="#voc" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.VOCSegmentation">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">VOCSegmentation</code><span class="sig-paren">(</span><em>root: str</em>, <em>year: str = '2012'</em>, <em>image_set: str = 'train'</em>, <em>download: bool = False</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>transforms: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCSegmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCSegmentation" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a> Segmentation Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the VOC Dataset.</li>
<li><strong>year</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset year, supports years <code class="docutils literal notranslate"><span class="pre">&quot;2007&quot;</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;2012&quot;</span></code>.</li>
<li><strong>image_set</strong> (<em>string</em><em>, </em><em>optional</em>) – Select the image_set to use, <code class="docutils literal notranslate"><span class="pre">&quot;train&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;trainval&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;val&quot;</span></code>. If
<code class="docutils literal notranslate"><span class="pre">year==&quot;2007&quot;</span></code>, can also be <code class="docutils literal notranslate"><span class="pre">&quot;test&quot;</span></code>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.VOCSegmentation.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCSegmentation.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCSegmentation.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is the image segmentation.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.VOCDetection">
<em class="property">class </em><code class="descclassname">torchvision.datasets.</code><code class="descname">VOCDetection</code><span class="sig-paren">(</span><em>root: str</em>, <em>year: str = '2012'</em>, <em>image_set: str = 'train'</em>, <em>download: bool = False</em>, <em>transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>target_transform: Union[Callable</em>, <em>NoneType] = None</em>, <em>transforms: Union[Callable</em>, <em>NoneType] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCDetection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCDetection" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a> Detection Dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>root</strong> (<em>string</em>) – Root directory of the VOC Dataset.</li>
<li><strong>year</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset year, supports years <code class="docutils literal notranslate"><span class="pre">&quot;2007&quot;</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;2012&quot;</span></code>.</li>
<li><strong>image_set</strong> (<em>string</em><em>, </em><em>optional</em>) – Select the image_set to use, <code class="docutils literal notranslate"><span class="pre">&quot;train&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;trainval&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;val&quot;</span></code>. If
<code class="docutils literal notranslate"><span class="pre">year==&quot;2007&quot;</span></code>, can also be <code class="docutils literal notranslate"><span class="pre">&quot;test&quot;</span></code>.</li>
<li><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.
(default: alphabetic indexing of VOC’s 20 classes).</li>
<li><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></li>
<li><strong>target_transform</strong> (<em>callable</em><em>, </em><em>required</em>) – A function/transform that takes in the
target and transforms it.</li>
<li><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="torchvision.datasets.VOCDetection.__getitem__">
<code class="descname">__getitem__</code><span class="sig-paren">(</span><em>index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCDetection.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCDetection.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">(image, target) where target is a dictionary of the XML tree.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="io.html" class="btn btn-neutral float-right" title="torchvision.io" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="torchvision" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchvision.datasets</a><ul>
<li><a class="reference internal" href="#celeba">CelebA</a></li>
<li><a class="reference internal" href="#cifar">CIFAR</a></li>
<li><a class="reference internal" href="#cityscapes">Cityscapes</a></li>
<li><a class="reference internal" href="#coco">COCO</a><ul>
<li><a class="reference internal" href="#captions">Captions</a></li>
<li><a class="reference internal" href="#detection">Detection</a></li>
</ul>
</li>
<li><a class="reference internal" href="#datasetfolder">DatasetFolder</a></li>
<li><a class="reference internal" href="#emnist">EMNIST</a></li>
<li><a class="reference internal" href="#fakedata">FakeData</a></li>
<li><a class="reference internal" href="#fashion-mnist">Fashion-MNIST</a></li>
<li><a class="reference internal" href="#flickr">Flickr</a></li>
<li><a class="reference internal" href="#hmdb51">HMDB51</a></li>
<li><a class="reference internal" href="#imagefolder">ImageFolder</a></li>
<li><a class="reference internal" href="#imagenet">ImageNet</a></li>
<li><a class="reference internal" href="#kinetics-400">Kinetics-400</a></li>
<li><a class="reference internal" href="#kmnist">KMNIST</a></li>
<li><a class="reference internal" href="#lsun">LSUN</a></li>
<li><a class="reference internal" href="#mnist">MNIST</a></li>
<li><a class="reference internal" href="#omniglot">Omniglot</a></li>
<li><a class="reference internal" href="#phototour">PhotoTour</a></li>
<li><a class="reference internal" href="#places365">Places365</a></li>
<li><a class="reference internal" href="#qmnist">QMNIST</a></li>
<li><a class="reference internal" href="#sbd">SBD</a></li>
<li><a class="reference internal" href="#sbu">SBU</a></li>
<li><a class="reference internal" href="#stl10">STL10</a></li>
<li><a class="reference internal" href="#svhn">SVHN</a></li>
<li><a class="reference internal" href="#ucf101">UCF101</a></li>
<li><a class="reference internal" href="#usps">USPS</a></li>
<li><a class="reference internal" href="#voc">VOC</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript">
           var DOCUMENTATION_OPTIONS = {
               URL_ROOT:'./',
               VERSION:'master',
               LANGUAGE:'None',
               COLLAPSE_INDEX:false,
               FILE_SUFFIX:'.html',
               HAS_SOURCE:  true,
               SOURCELINK_SUFFIX: '.txt'
           };
       </script>
         <script type="text/javascript" src="_static/jquery.js"></script>
         <script type="text/javascript" src="_static/underscore.js"></script>
         <script type="text/javascript" src="_static/doctools.js"></script>
         <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>